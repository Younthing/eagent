# Literature Agent (Upgraded)

å¹¶è¡Œ Map-Reduce æ–‡çŒ®åˆ†ææ™ºèƒ½ä½“ç¤ºä¾‹ï¼Œé›†æˆ LangChain Hub æç¤ºè¯ã€LangSmith è¿½è¸ªã€ä¸Šä¸‹æ–‡åˆ‡ç‰‡ã€èŠ‚ç‚¹çº§é‡è¯•ä¸ HITL æ§åˆ¶ã€‚

---

## 1. ç›®å½•ç»“æ„

```text
eagent/
â”œâ”€â”€ .env.example                # ç¯å¢ƒå˜é‡æ¨¡ç‰ˆ
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ main.py                     # CLI + HITL
â”œâ”€â”€ src/
â”‚   â””â”€â”€ eagent/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ state.py            # æ•°æ®ç»“æ„
â”‚       â”œâ”€â”€ prompts.py          # Hub æ‹‰å– + æœ¬åœ°å…œåº•
â”‚       â”œâ”€â”€ graph.py            # ç¼–æ’ (å« interrupt_before)
â”‚       â”œâ”€â”€ utils/
â”‚       â”‚   â””â”€â”€ parsing.py      # @traceable æ–‡æ¡£è§£æ
â”‚       â””â”€â”€ nodes/
â”‚           â”œâ”€â”€ planner.py      # è§„åˆ’ + Context Slicing
â”‚           â”œâ”€â”€ worker.py       # é‡è¯• + æ ¡éªŒ
â”‚           â””â”€â”€ aggregator.py   # æ±‡æ€»
â””â”€â”€ tests/
    â””â”€â”€ eval.py                 # LangSmith KV è¯„ä¼°
```

---

## 2. çŠ¶æ€ä¸æ¨¡å‹ (`src/eagent/state.py`)

```python
import operator
from typing import Annotated, Dict, List
from typing_extensions import TypedDict
from pydantic import BaseModel, Field

class Task(BaseModel):
    dimension: str
    section_filter: str
    search_query: str

class AnalysisResult(BaseModel):
    dimension: str
    content: str
    is_valid: bool = Field(default=True)
    retry_count: int = Field(default=0)

class AgentState(TypedDict):
    doc_structure: Dict[str, str]
    plan: List[Task]
    analyses: Annotated[List[AnalysisResult], operator.add]
    final_report: str
```

---

## 3. Prompt Hub (`src/eagent/prompts.py`)

```python
from langchain import hub
from langchain_core.prompts import ChatPromptTemplate

_DEFAULT_PLANNER = ChatPromptTemplate.from_template(
    "åˆ†ææ–‡æ¡£ç»“æ„: {doc_keys}ã€‚\n"
    "è¯·ç”Ÿæˆåˆ†æè®¡åˆ’ã€‚å¯¹äºæ¯ä¸ªç»´åº¦ï¼ŒåŠ¡å¿…æŒ‡å®šæœ€ç›¸å…³çš„ 'section_filter' (ç« èŠ‚Key)ã€‚"
)

_DEFAULT_WORKER = ChatPromptTemplate.from_template(
    "ä½ è´Ÿè´£åˆ†æ {dimension}ã€‚\n"
    "è¯·ä»…åŸºäºä»¥ä¸‹æä¾›çš„ç‰‡æ®µè¿›è¡Œåˆ†æï¼Œä¸è¦ç¼–é€ ã€‚\n"
    "ç‰‡æ®µå†…å®¹:\n{context}"
)

def get_prompt(repo_id: str, default: ChatPromptTemplate) -> ChatPromptTemplate:
    try:
        return hub.pull(repo_id)
    except Exception as exc:
        print(f"âš ï¸ Warning: Failed to pull prompt {repo_id}, using default. Error: {exc}")
        return default

planner_prompt = get_prompt("my-org/paper-analysis-planner", _DEFAULT_PLANNER)
worker_prompt = get_prompt("my-org/paper-section-analyzer", _DEFAULT_WORKER)
```

---

## 4. Traceable è§£æ (`src/eagent/utils/parsing.py`)

```python
from typing import Dict
from langsmith import traceable

@traceable(run_type="parser", name="PDF Structure Parser")
def parse_pdf_structure(file_path: str) -> Dict[str, str]:
    return {
        "abstract": "This paper proposes a new Transformer architecture...",
        "methods": "We utilized a 12-layer attention mechanism with...",
        "results": "Our model achieved 98.5% accuracy on the test set...",
        "conclusion": "Future work includes...",
    }
```

---

## 5. èŠ‚ç‚¹å®ç°

### 5.1 Planner (`src/eagent/nodes/planner.py`)

```python
from typing import List
from langchain_openai import ChatOpenAI
from pydantic import BaseModel
from eagent.prompts import planner_prompt
from eagent.state import AgentState, Task

llm = ChatOpenAI(model="gpt-4o", temperature=0)

class PlanningOutput(BaseModel):
    tasks: List[Task]

def plan_node(state: AgentState):
    doc_keys = list(state["doc_structure"].keys())
    chain = planner_prompt | llm.with_structured_output(PlanningOutput)
    result: PlanningOutput = chain.invoke({"doc_keys": str(doc_keys)})
    return {"plan": result.tasks}
```

### 5.2 Worker (`src/eagent/nodes/worker.py`)

```python
from langchain_openai import ChatOpenAI
from eagent.prompts import worker_prompt
from eagent.state import AnalysisResult, Task

llm = ChatOpenAI(model="gpt-4o", temperature=0)

def extract_context(doc: dict, task: Task) -> str:
    content = doc.get(task.section_filter)
    if not content:
        return str(doc)[:2000]
    return content

def worker_node(state: dict):
    task: Task = state["task"]
    doc = state["doc_structure"]
    context = extract_context(doc, task)

    max_retries = 3
    current_try = 0
    last_error = None

    while current_try < max_retries:
        try:
            chain = worker_prompt | llm.with_structured_output(AnalysisResult)
            result: AnalysisResult = chain.invoke(
                {"dimension": task.dimension, "context": context}
            )
            if len(result.content) < 10:
                raise ValueError("Content too short, looks like hallucination.")
            result.retry_count = current_try
            return {"analyses": [result]}
        except Exception as exc:
            current_try += 1
            last_error = exc
            print(f"Node retry {current_try}/{max_retries} for {task.dimension}: {exc}")

    return {
        "analyses": [
            AnalysisResult(
                dimension=task.dimension,
                content=f"Analysis Failed after retries. Error: {last_error}",
                is_valid=False,
                retry_count=current_try,
            )
        ]
    }
```

### 5.3 Aggregator (`src/eagent/nodes/aggregator.py`)

```python
from eagent.state import AgentState

def aggregator_node(state: AgentState):
    texts = [
        f"## {a.dimension}\n{a.content}"
        for a in state.get("analyses", [])
        if a.is_valid
    ]
    return {"final_report": "\n\n".join(texts)}
```

---

## 6. å›¾ç¼–æ’ (`src/eagent/graph.py`)

```python
from langgraph.checkpoint.memory import MemorySaver
from langgraph.constants import Send, START, END
from langgraph.graph import StateGraph

from eagent.nodes.aggregator import aggregator_node
from eagent.nodes.planner import plan_node
from eagent.nodes.worker import worker_node
from eagent.state import AgentState

def map_analyses(state: AgentState):
    return [
        Send("analyzer", {"task": task, "doc_structure": state["doc_structure"]})
        for task in state["plan"]
    ]

def build_graph():
    workflow = StateGraph(AgentState)
    workflow.add_node("planner", plan_node)
    workflow.add_node("analyzer", worker_node)
    workflow.add_node("summarizer", aggregator_node)
    workflow.add_edge(START, "planner")
    workflow.add_conditional_edges("planner", map_analyses, ["analyzer"])
    workflow.add_edge("analyzer", "summarizer")
    workflow.add_edge("summarizer", END)
    checkpointer = MemorySaver()
    return workflow.compile(checkpointer=checkpointer, interrupt_before=["analyzer"])
```

---

## 7. HITL CLI (`main.py`)

```python
import typer
from rich.console import Console
from rich.prompt import Prompt
from eagent.graph import build_graph
from eagent.state import Task
from eagent.utils.parsing import parse_pdf_structure

app = typer.Typer()
console = Console()

@app.command()
def analyze(file_path: str):
    doc_structure = parse_pdf_structure(file_path)
    app_graph = build_graph()
    thread_config = {"configurable": {"thread_id": "session_user_1"}}
    initial_state = {"doc_structure": doc_structure, "plan": [], "analyses": []}

    console.print("[bold blue]ğŸ¤– AI æ­£åœ¨è§„åˆ’åˆ†æä»»åŠ¡...[/bold blue]")
    for _ in app_graph.stream(initial_state, thread_config):
        pass

    snapshot = app_graph.get_state(thread_config)
    current_plan = snapshot.values["plan"]

    console.print("\n[yellow]=== AI æè®®çš„åˆ†æè®¡åˆ’ ===[/yellow]")
    for i, task in enumerate(current_plan):
        console.print(f"{i+1}. ç»´åº¦: {task.dimension} -> ç« èŠ‚: {task.section_filter}")

    action = Prompt.ask("ä¸‹ä¸€æ­¥æ“ä½œ?", choices=["continue", "add", "quit"], default="continue")
    if action == "quit":
        return
    if action == "add":
        new_dim = Prompt.ask("è¾“å…¥æ–°ç»´åº¦åç§°")
        new_key = Prompt.ask("è¾“å…¥è¯»å–ç« èŠ‚Key", default="methods")
        new_task = Task(dimension=new_dim, section_filter=new_key, search_query=new_dim)
        app_graph.update_state(thread_config, {"plan": current_plan + [new_task]})

    console.print("ğŸš€ å¹¶è¡Œåˆ†æä¸­...")
    final_output = None
    for event in app_graph.stream(None, thread_config):
        if "summarizer" in event:
            final_output = event["summarizer"]
    if final_output:
        console.print("\n[bold green]=== æœ€ç»ˆæŠ¥å‘Š ===[/bold green]")
        console.print(final_output["final_report"])
```

---

## 8. è¯„ä¼° (`tests/eval.py`)

åŸºäº LangSmith KV æ•°æ®é›†çš„è‡ªåŠ¨åŒ–è¯„ä¼°ï¼Œä½¿ç”¨ `load_evaluator("labeled_criteria")` æˆ–è‡ªå®šä¹‰ LLM-as-a-judgeã€‚
