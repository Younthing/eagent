# LLM Providers
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-...

# LangSmith / Tracing
LANGSMITH_TRACING=true
LANGSMITH_ENDPOINT=https://api.smith.langchain.com
LANGSMITH_API_KEY=lsv2-...
LANGSMITH_PROJECT=literature-agent


# Retrieval Query Planner (Milestone 4)
# Used when running retrieval with `query_planner=llm` (BM25/SPLADE multi-query generation).
QUERY_PLANNER_MODEL=openai:gpt-4o-mini
# QUERY_PLANNER_MODEL_PROVIDER=openai
QUERY_PLANNER_TEMPERATURE=0.0
# QUERY_PLANNER_TIMEOUT=30
# QUERY_PLANNER_MAX_TOKENS=512
QUERY_PLANNER_MAX_RETRIES=2

# SPLADE Retrieval (Milestone 4/5)
# Use a local model path to avoid gated model access.
SPLADE_MODEL_ID=./models/splade_distil_CoCodenser_large
# SPLADE_DEVICE=mps
# SPLADE_QUERY_MAX_LENGTH=64
# SPLADE_DOC_MAX_LENGTH=256
# SPLADE_BATCH_SIZE=8
# SPLADE_HF_TOKEN=hf-...

# Retrieval Reranker (optional, post-RRF)
RERANKER_MODEL_ID=ncbi/MedCPT-Cross-Encoder
# RERANKER_DEVICE=cpu  # cpu|cuda|mps
RERANKER_MAX_LENGTH=512
RERANKER_BATCH_SIZE=8
RERANKER_TOP_N=50

# Evidence Relevance Validator (Milestone 7)
# Used when running relevance validation with `relevance_validator=llm`.
RELEVANCE_MODEL=openai:gpt-4o-mini
# RELEVANCE_MODEL_PROVIDER=openai
RELEVANCE_TEMPERATURE=0.0
# RELEVANCE_TIMEOUT=30
# RELEVANCE_MAX_TOKENS=512
RELEVANCE_MAX_RETRIES=2

# Evidence Consistency Validator (Milestone 7)
# Used when running consistency validation with `consistency_validator=llm`.
CONSISTENCY_MODEL=openai:gpt-4o-mini
# CONSISTENCY_MODEL_PROVIDER=openai
CONSISTENCY_TEMPERATURE=0.0
# CONSISTENCY_TIMEOUT=30
# CONSISTENCY_MAX_TOKENS=512
CONSISTENCY_MAX_RETRIES=2

# Domain Reasoning (Milestone 8)
# Used when running D1/D2 reasoning with `d1_randomization_node` / `d2_deviations_node`.
D1_MODEL=openai:gpt-4o-mini
# D1_MODEL_PROVIDER=openai
D1_TEMPERATURE=0.0
# D1_TIMEOUT=60
# D1_MAX_TOKENS=800
D1_MAX_RETRIES=2

D2_MODEL=openai:gpt-4o-mini
# D2_MODEL_PROVIDER=openai
D2_TEMPERATURE=0.0
# D2_TIMEOUT=60
# D2_MAX_TOKENS=800
D2_MAX_RETRIES=2

# Docling Settings
DOCLING_LAYOUT_MODEL=docling_layout_heron
DOCLING_CHUNKER_MODEL=malteos/PubMedNCL # 针对论文优化
# DOCLING_CHUNKER_MODEL=sentence-transformers/all-MiniLM-L6-v2
DOCLING_CHUNKER_MAX_TOKENS=640
